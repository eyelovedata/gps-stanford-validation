{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd6afa7-b651-4962-8d21-d6371648e5ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.layers import Input, Add, GaussianNoise, MaxPooling1D, BatchNormalization, Dense, Dropout,Reshape,Flatten, Conv1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6bd31e-fcbe-4a18-b30b-755b7a6604ec",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107a2298-8899-4945-ab85-d6eca10f051a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AE_SOURCE = \"frozen\"\n",
    "\n",
    "if AE_SOURCE == \"frozen\":\n",
    "    meds_path = \"./processed_data/drugs_stack_autoencoder.csv\"\n",
    "    diags_path = \"./processed_data/features_diagnoses_stack_autoencoder.csv\"\n",
    "else:\n",
    "    meds_path = \"./processed_data/4_21_retrain_drugs_stack_autoencoder.csv\"\n",
    "    diags_path = \"./processed_data/4_21_retrain_features_diagnoses_stack_autoencoder.csv\"\n",
    "\n",
    "meds = pd.read_csv(meds_path)\n",
    "diags = pd.read_csv(diags_path)\n",
    "\n",
    "demo_labs = pd.read_csv(\"./processed_data/demo_labs_mice_imputed_scaled.csv\")  \n",
    "cohort = pd.read_csv(\"processed_data/cohort.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b497e8-b9d7-4359-8423-8aa40a9b6c65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo_labs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3016348c-7fa0-4fd5-b12a-5b9e83bedbef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meds.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eabbe4b-4dbd-4dda-9e6d-48bb687653ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diags.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e67f5e6-9998-4f30-99a9-913e2afb01d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cohort.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb5441b-2707-43a8-8224-ede52bf8763f",
   "metadata": {},
   "source": [
    "# Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bdb86f-adbb-4b45-8355-db0ffb597ed4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meds_diag = pd.merge(meds, diags, on='MRN', how='inner')\n",
    "\n",
    "\n",
    "meds_diag_demo_labs = pd.merge(meds_diag, demo_labs, on='MRN', how='inner')\n",
    "\n",
    "meds_diag_demo_labs_cohort = pd.merge(meds_diag_demo_labs, cohort[['MRN', 'outcome']], on='MRN', how='inner')\n",
    "\n",
    "meds_diag_demo_labs_cohort = meds_diag_demo_labs_cohort.set_index('MRN')\n",
    "\n",
    "meds_diag_demo_labs_cohort = meds_diag_demo_labs_cohort.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a212d8c-fbea-4ca9-b7c5-c467d0bb6c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meds_diag_demo_labs_cohort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57b06dd-35b5-4654-8ae4-21f5cacc8c3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(meds_diag_demo_labs_cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3a30fb-9716-4845-9327-b511a9e1a9e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098dbc7a-62d3-4cf7-9c5f-0197d1b8cc11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = meds_diag_demo_labs_cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd8b75f-f478-4dac-b78e-dce19936b8fb",
   "metadata": {},
   "source": [
    "# Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01adf2be-6e24-42d7-bd57-5b06bca77b87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(df['outcome'])\n",
    "total = neg + pos\n",
    "imbalance = pos / total\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100*imbalance))\n",
    "\n",
    "df_Y = df['outcome']\n",
    "df_X = df.drop(columns = ['outcome'], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7709c165-e5a5-4d48-8380-9a582d3ab4a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a849e406-6a78-4006-83ff-6edc61d67b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size=0.20, shuffle=True, random_state=42)\n",
    "# Initial split into training and temporary sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(df_X, df_Y, test_size=0.30, shuffle=True, random_state=42)\n",
    "\n",
    "# Further split the temporary set into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=(2. / 3), shuffle=True, random_state=42)\n",
    "\n",
    "# Now you have X_train, X_val, X_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fa7159-bd27-4a18-9358-946234bc234d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'Features Train - {X_train.shape}, Outcomes Train - {y_train.shape}')\n",
    "print(f'Features Val - {X_val.shape}, Outcomes Val - {y_val.shape}')\n",
    "print(f'Features Test - {X_test.shape}, Outcomes Test - {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a105bd3-b251-4a4c-a8cf-5831f1f12883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test.to_csv('data_test_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171806be-6992-48d0-a66e-5683f7179772",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364f6e43-0782-4535-8743-01090b733073",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Finetuning the model using the autoencoder features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b1247e-cc75-4f57-9e66-357e39b20da5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_save_model(X_train, y_train, X_val, y_val, X_test, y_test, outputmodel, outputpredictions, outputvalpredictions, N):\n",
    "    \n",
    "    # Load the original model\n",
    "    model = keras.models.load_model(\"models/model_ALL_OF_US.keras\")\n",
    "    \n",
    "    # Freeze all layers except for the last N\n",
    "    print(\"All layers frozen except for last \", N)\n",
    "    if N == 0 :\n",
    "        for layer in model.layers: \n",
    "            layer.trainable = False\n",
    "    else :\n",
    "        for layer in model.layers[:-N]: \n",
    "            layer.trainable = False\n",
    "    \n",
    "    # Compile the model\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_auc', \n",
    "        verbose=1,\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        restore_best_weights=True)\n",
    "\n",
    "    metrics_list = [\n",
    "        keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        keras.metrics.AUC(name='auc'),\n",
    "        keras.metrics.AUC(name='prc', curve='PR'),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "    ]\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss=keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=metrics_list)\n",
    "\n",
    "    # Continue training on new data\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_data=(X_val, y_val), epochs=150, shuffle=True,\n",
    "                        batch_size=64, class_weight=class_weight, callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    results = model.evaluate(X_test, y_test, batch_size=64, verbose=0)\n",
    "    for name, value in zip(model.metrics_names, results):\n",
    "        print(name, ': ', value)\n",
    "        \n",
    "    # Predict on the test set\n",
    "    test_predictions = model.predict(X_test, batch_size=64)\n",
    "    df_test_predictions = pd.DataFrame(test_predictions, columns=[\"Prediction\"])\n",
    "    df_test_predictions.index = X_test.index\n",
    "    \n",
    "    print(\"Saving test predictions to \", outputpredictions) \n",
    "    df_test_predictions.to_csv(outputpredictions)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    val_predictions = model.predict(X_val, batch_size=64)\n",
    "    df_val_predictions = pd.DataFrame(val_predictions, columns=[\"Prediction\"])\n",
    "    df_val_predictions.index = X_val.index\n",
    "    \n",
    "    print(\"Saving validation predictions to \", outputvalpredictions) \n",
    "    df_val_predictions.to_csv(outputvalpredictions)\n",
    "    \n",
    "    # Save the model\n",
    "    print(\"Saving model to \", outputmodel) \n",
    "    model.save(outputmodel)  # Saves in Keras format\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa156e-2024-4806-8238-74034551fd42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sweep: % of training data (in 20% increments) Ã— number of unfrozen layers\n",
    "Nlist = [20, 40, 60, 80, 100]\n",
    "num_unfrozen_layers = [0, 1, 3, 6, 7, 8, 9, 11, 12, 15, 16, 18]\n",
    "\n",
    "# Tag outputs based on which AE embeddings were used to build df (frozen vs retrained).\n",
    "# AE_SOURCE should be set earlier in the notebook (e.g., \"frozen\" or \"retrained\").\n",
    "run_tag = \"retrain_autoencoders_\" if AE_SOURCE == \"retrained\" else \"\"\n",
    "\n",
    "for pct in Nlist:\n",
    "    n_train = int(len(X_train) * (pct / 100.0))\n",
    "\n",
    "    X_sub = X_train.head(n_train)\n",
    "    y_sub = y_train.head(n_train)\n",
    "\n",
    "    for n_unfrozen in num_unfrozen_layers:\n",
    "        train_save_model(\n",
    "            X_sub, y_sub,\n",
    "            X_val, y_val,\n",
    "            X_test, y_test,\n",
    "            f\"models_4_21/{run_tag}model_AoUencoder_StanfordFinetune-{n_unfrozen}-{pct}pct.keras\",\n",
    "            f\"out/{run_tag}final_test_predictions_AoUencoder_StanfordFinetune-{n_unfrozen}-{pct}pct.csv\",\n",
    "            f\"out/{run_tag}final_val_predictions_AoUencoder_StanfordFinetune-{n_unfrozen}-{pct}pct.csv\",\n",
    "            n_unfrozen,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
